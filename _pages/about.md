---
layout: about
title: about
permalink: /
subtitle: <a href='#'>Research Fellow</a>. Centre for AI Fundamentals, Department of Computer Science. University of Manchester. UK.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p> </p>
    <p> </p>
    <p> </p>

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

Artificial Intelligence systems are inherently vulnerable to a range of adversarial threats, including adversarial and backdoor attacks. My research centers on developing mechanisms for AI Safety and Security, spanning both fundamental theory and practical deployment. I focus on ensuring that AI systems remain secure, trustworthy, and robust, particularly in adversarial or malicious settings. This includes designing methods that preserve the privacy of sensitive data and enable reliable predictions and safe decision-making under adversarial threats and distribution shift. I am also deeply interested in the underlying principles of out-of-distribution detection, data manifold learning, machine unlearning and the robustness of Language Vision Models and Large Language Models. I aim to make AI-driven technologies, such as healthcare tools, online platforms, and autonomous systems, more reliable and safer for everyone to use.
